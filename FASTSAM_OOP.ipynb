{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxSnJZ9AwI2W1ahsLOYv+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juaaju/Antropometri-Digital/blob/main/FASTSAM_OOP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwXvr-ABjgIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8dc3f14-d7b2-4928-f8b7-2846561465d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FastSAM'...\n",
            "remote: Enumerating objects: 1221, done.\u001b[K\n",
            "remote: Counting objects: 100% (386/386), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 1221 (delta 334), reused 305 (delta 305), pack-reused 835\u001b[K\n",
            "Receiving objects: 100% (1221/1221), 72.46 MiB | 13.20 MiB/s, done.\n",
            "Resolving deltas: 100% (487/487), done.\n",
            "--2024-02-28 11:49:10--  https://huggingface.co/spaces/An-619/FastSAM/resolve/main/weights/FastSAM.pt\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.5, 13.35.7.38, 13.35.7.81, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/71/c3/71c3ec5a83f3fc374665cec9240f614262e29088fca1a18732571e13c7084f1b/c0be4e7ddbe4c15333d15a859c676d053c486d0a746a3be6a7a9790d52a9b6d7?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27FastSAM.pt%3B+filename%3D%22FastSAM.pt%22%3B&Expires=1709380150&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTM4MDE1MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy83MS9jMy83MWMzZWM1YTgzZjNmYzM3NDY2NWNlYzkyNDBmNjE0MjYyZTI5MDg4ZmNhMWExODczMjU3MWUxM2M3MDg0ZjFiL2MwYmU0ZTdkZGJlNGMxNTMzM2QxNWE4NTljNjc2ZDA1M2M0ODZkMGE3NDZhM2JlNmE3YTk3OTBkNTJhOWI2ZDc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=U9z%7EbUZtiA6W9ZV4BXC83DZPf0JxWbSx6hN2dES8v3raxHVATTxqBdvXQo6KIs-4i6C-j%7ELOiC8R-8waVPg45jrPM480AgTZdbXpvgSw2LG0G1rVwXqnWt-i3UvvrpFMen2864S6x87zLl7RB2QeRovfx9z-k6U8Tj73-hg09pn95Eb02sKETPLMai5kXk68UCYXPhQiStKkF6pfRn1z6sKZeofI2nlX5HGq87KX65D9sNCT5D5Q5DEfrLGcu7%7EkwlvDyCNIbKo4-EAl0i7k-zxV2-XZ2dwQr3H1YNxCayO3ytWslecI%7EKuKFYaeJKycbQOUHOnv6VCQs6ygRHbNKQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-02-28 11:49:10--  https://cdn-lfs.huggingface.co/repos/71/c3/71c3ec5a83f3fc374665cec9240f614262e29088fca1a18732571e13c7084f1b/c0be4e7ddbe4c15333d15a859c676d053c486d0a746a3be6a7a9790d52a9b6d7?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27FastSAM.pt%3B+filename%3D%22FastSAM.pt%22%3B&Expires=1709380150&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTM4MDE1MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy83MS9jMy83MWMzZWM1YTgzZjNmYzM3NDY2NWNlYzkyNDBmNjE0MjYyZTI5MDg4ZmNhMWExODczMjU3MWUxM2M3MDg0ZjFiL2MwYmU0ZTdkZGJlNGMxNTMzM2QxNWE4NTljNjc2ZDA1M2M0ODZkMGE3NDZhM2JlNmE3YTk3OTBkNTJhOWI2ZDc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=U9z%7EbUZtiA6W9ZV4BXC83DZPf0JxWbSx6hN2dES8v3raxHVATTxqBdvXQo6KIs-4i6C-j%7ELOiC8R-8waVPg45jrPM480AgTZdbXpvgSw2LG0G1rVwXqnWt-i3UvvrpFMen2864S6x87zLl7RB2QeRovfx9z-k6U8Tj73-hg09pn95Eb02sKETPLMai5kXk68UCYXPhQiStKkF6pfRn1z6sKZeofI2nlX5HGq87KX65D9sNCT5D5Q5DEfrLGcu7%7EkwlvDyCNIbKo4-EAl0i7k-zxV2-XZ2dwQr3H1YNxCayO3ytWslecI%7EKuKFYaeJKycbQOUHOnv6VCQs6ygRHbNKQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.35.7.14, 13.35.7.113, 13.35.7.99, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.35.7.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 144943063 (138M) [application/zip]\n",
            "Saving to: ‘FastSAM.pt’\n",
            "\n",
            "FastSAM.pt          100%[===================>] 138.23M  65.5MB/s    in 2.1s    \n",
            "\n",
            "2024-02-28 11:49:13 (65.5 MB/s) - ‘FastSAM.pt’ saved [144943063/144943063]\n",
            "\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 3)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 6)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 7)) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 8)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 9)) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 10)) (4.66.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 12)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r FastSAM/requirements.txt (line 13)) (0.13.1)\n",
            "Collecting gradio==3.35.2 (from -r FastSAM/requirements.txt (line 15))\n",
            "  Downloading gradio-3.35.2-py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ultralytics==8.0.120 (from -r FastSAM/requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.0.120-py3-none-any.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.7/611.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (3.9.3)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.7 (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading gradio_client-0.10.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (0.20.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (3.0.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (2.1.5)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (1.25.2)\n",
            "Collecting orjson (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (2.6.1)\n",
            "Collecting pydub (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (2.16.1)\n",
            "Collecting python-multipart (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting semantic-version (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.120->-r FastSAM/requirements.txt (line 18)) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r FastSAM/requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r FastSAM/requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r FastSAM/requirements.txt (line 2)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r FastSAM/requirements.txt (line 2)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r FastSAM/requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r FastSAM/requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r FastSAM/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r FastSAM/requirements.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r FastSAM/requirements.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r FastSAM/requirements.txt (line 6)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r FastSAM/requirements.txt (line 6)) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r FastSAM/requirements.txt (line 8)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r FastSAM/requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r FastSAM/requirements.txt (line 8)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r FastSAM/requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r FastSAM/requirements.txt (line 8)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r FastSAM/requirements.txt (line 8)) (2.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r FastSAM/requirements.txt (line 12)) (2023.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (0.12.1)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (2.0.3)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->-r FastSAM/requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (8.1.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (4.0.3)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio==3.35.2->-r FastSAM/requirements.txt (line 15))\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (2.16.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r FastSAM/requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (0.18.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (1.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.35.2->-r FastSAM/requirements.txt (line 15)) (1.2.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=cf475bbe06a8c14ec97b9c3eb17afba6a98583af20e096b6132a9929acb962b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, semantic-version, python-multipart, orjson, markdown-it-py, h11, aiofiles, uvicorn, starlette, mdit-py-plugins, httpcore, httpx, fastapi, ultralytics, gradio-client, gradio\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: mdit-py-plugins\n",
            "    Found existing installation: mdit-py-plugins 0.4.0\n",
            "    Uninstalling mdit-py-plugins-0.4.0:\n",
            "      Successfully uninstalled mdit-py-plugins-0.4.0\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.110.0 ffmpy-0.3.2 gradio-3.35.2 gradio-client-0.10.1 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 orjson-3.9.15 pydub-0.25.1 python-multipart-0.0.9 semantic-version-2.10.0 starlette-0.36.3 ultralytics-8.0.120 uvicorn-0.27.1 websockets-11.0.3\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-bj8_ghf_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-bj8_ghf_\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu121)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=20b68577dd37e7b086f6e3b61a9fdc28bb9496ecbf88cea0d85f0f2a256620d4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-is80igd3/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.3\n",
            "Mounted at /content/drive\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/myProjek/ANTROPOMETRI/all.rar\n",
            "\n",
            "Extracting  /content/.gitignore                                          \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/baby5-side2.jpeg                                    \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/baby5-up.jpeg                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/data ukur bayi.xlsx                                 \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/detect.py                                           \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/export.py                                           \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/hubconf.py                                          \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/mediapipe-0.10.5-cp311-cp311-win_amd64.whl          \b\b\b\b  8%\b\b\b\b 16%\b\b\b\b 24%\b\b\b\b 32%\b\b\b\b 40%\b\b\b\b 47%\b\b\b\b 55%\b\b\b\b 63%\b\b\b\b 71%\b\b\b\b 79%\b\b\b\b 87%\b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  /content/model.py                                            \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  /content/Nasution et al_revision.pdf                         \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  /content/pacman                                              \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  /content/pose.py                                             \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  /content/PROGRES CODE UTAMA.pdf                              \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  /content/PROGRES CODE UTAMA.pptx                             \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/requirements.txt                                    \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/sam.py                                              \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/tempCodeRunnerFile.py                               \b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/myProjek/ANTROPOMETRI/model.rar\n",
            "\n",
            "Extracting  /content/pose_landmarker_lite.task                           \b\b\b\b 23%\b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  /content/best.pt                                             \b\b\b\b 49%\b\b\b\b 72%\b\b\b\b 95%\b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/myProjek/ANTROPOMETRI/models.rar\n",
            "\n",
            "Creating    /content/models                                           OK\n",
            "Extracting  /content/models/common.py                                    \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/custom_yolov5n.yaml                          \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/custom_yolov5s.yaml                          \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/experimental.py                              \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Creating    /content/models/hub                                       OK\n",
            "Extracting  /content/models/hub/anchors.yaml                             \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov3-spp.yaml                          \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov3-tiny.yaml                         \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov3.yaml                              \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-bifpn.yaml                        \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-fpn.yaml                          \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-p2.yaml                           \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-p34.yaml                          \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-p6.yaml                           \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-p7.yaml                           \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-panet.yaml                        \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5l6.yaml                            \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5m6.yaml                            \b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5n6.yaml                            \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5s-ghost.yaml                       \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5s-transformer.yaml                 \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5s6.yaml                            \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5x6.yaml                            \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/tf.py                                        \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolo.py                                      \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolov5l.yaml                                 \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolov5m.yaml                                 \b\b\b\b 59%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolov5n.yaml                                 \b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolov5s.yaml                                 \b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolov5x.yaml                                 \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/__init__.py                                  \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Creating    /content/models/__pycache__                               OK\n",
            "Extracting  /content/models/__pycache__/common.cpython-310.pyc           \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/__pycache__/experimental.cpython-310.pyc     \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/__pycache__/yolo.cpython-310.pyc             \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/__pycache__/__init__.cpython-310.pyc         \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/myProjek/ANTROPOMETRI/utils.rar\n",
            "\n",
            "Creating    /content/utils                                            OK\n",
            "Extracting  /content/utils/activations.py                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/augmentations.py                              \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/autoanchor.py                                 \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/autobatch.py                                  \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Creating    /content/utils/aws                                        OK\n",
            "Extracting  /content/utils/aws/mime.sh                                   \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/aws/resume.py                                 \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/aws/userdata.sh                               \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/aws/__init__.py                               \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/benchmarks.py                                 \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/callbacks.py                                  \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/dataloaders.py                                \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Creating    /content/utils/docker                                     OK\n",
            "Extracting  /content/utils/docker/.dockerignore                          \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/docker/Dockerfile                             \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/docker/Dockerfile-arm64                       \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/docker/Dockerfile-cpu                         \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/downloads.py                                  \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Creating    /content/utils/flask_rest_api                             OK\n",
            "Extracting  /content/utils/flask_rest_api/example_request.py             \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/flask_rest_api/README.md                      \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/flask_rest_api/restapi.py                     \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/general.py                                    \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Creating    /content/utils/google_app_engine                          OK\n",
            "Extracting  /content/utils/google_app_engine/additional_requirements.txt     \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/google_app_engine/app.yaml                    \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/google_app_engine/Dockerfile                  \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Creating    /content/utils/loggers                                    OK\n",
            "Creating    /content/utils/loggers/wandb                              OK\n",
            "Extracting  /content/utils/loggers/wandb/log_dataset.py                  \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/loggers/wandb/README.md                       \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/loggers/wandb/sweep.py                        \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/loggers/wandb/sweep.yaml                      \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/loggers/wandb/wandb_utils.py                  \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/loggers/wandb/__init__.py                     \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Creating    /content/utils/loggers/wandb/__pycache__                  OK\n",
            "Extracting  /content/utils/loggers/wandb/__pycache__/wandb_utils.cpython-310.pyc     \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/loggers/wandb/__pycache__/__init__.cpython-310.pyc     \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/loggers/__init__.py                           \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Creating    /content/utils/loggers/__pycache__                        OK\n",
            "Extracting  /content/utils/loggers/__pycache__/__init__.cpython-310.pyc     \b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/loss.py                                       \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/metrics.py                                    \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/plots.py                                      \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/torch_utils.py                                \b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__init__.py                                   \b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Creating    /content/utils/__pycache__                                OK\n",
            "Extracting  /content/utils/__pycache__/augmentations.cpython-310.pyc     \b\b\b\b 59%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/autoanchor.cpython-310.pyc        \b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/autobatch.cpython-310.pyc         \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/callbacks.cpython-310.pyc         \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/dataloaders.cpython-310.pyc       \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/downloads.cpython-310.pyc         \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/general.cpython-310.pyc           \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/loss.cpython-310.pyc              \b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/metrics.cpython-310.pyc           \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/plots.cpython-310.pyc             \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/torch_utils.cpython-310.pyc       \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/utils/__pycache__/__init__.cpython-310.pyc          \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ],
      "source": [
        "def persiapan_file_fastsam():\n",
        "  !git clone https://github.com/CASIA-IVA-Lab/FastSAM.git\n",
        "  !wget https://huggingface.co/spaces/An-619/FastSAM/resolve/main/weights/FastSAM.pt\n",
        "  !pip install -r FastSAM/requirements.txt\n",
        "  !pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "def persiapan_environment_RIRI():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  path_to_rar_file1 = '/content/drive/MyDrive/myProjek/ANTROPOMETRI/all.rar'\n",
        "  path_to_rar_file2 = '/content/drive/MyDrive/myProjek/ANTROPOMETRI/model.rar'\n",
        "  path_to_rar_file3 = '/content/drive/MyDrive/myProjek/ANTROPOMETRI/models.rar'\n",
        "  path_to_rar_file4 = '/content/drive/MyDrive/myProjek/ANTROPOMETRI/utils.rar'\n",
        "  extracted_folder = '/content/'\n",
        "  !apt-get -qq install -y unrar\n",
        "  !unrar x {path_to_rar_file1} {extracted_folder}\n",
        "  !unrar x {path_to_rar_file2} {extracted_folder}\n",
        "  !unrar x {path_to_rar_file3} {extracted_folder}\n",
        "  !unrar x {path_to_rar_file4} {extracted_folder}\n",
        "\n",
        "persiapan_file_fastsam()\n",
        "persiapan_environment_RIRI()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSWks14E8oXP",
        "outputId": "5b61f216-4baf-4a8a-e9bf-d26a57480e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.8/34.8 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.23)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.10 sounddevice-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import cv2\n",
        "from mediapipe import solutions\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch"
      ],
      "metadata": {
        "id": "z_7pnB35m1Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from FastSAM.fastsam import FastSAM, FastSAMPrompt\n",
        "\n",
        "model = FastSAM('FastSAM.pt')\n",
        "DEVICE = 'cpu'"
      ],
      "metadata": {
        "id": "DvW6a6fhY69e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n",
        "\n",
        "# Fungsi Landmark\n",
        "def draw_landmarks_on_image(rgb_image, detection_result):\n",
        "  pose_landmarks_list = detection_result.pose_landmarks\n",
        "  annotated_image = np.copy(rgb_image)\n",
        "\n",
        "  # Loop through the detected poses to visualize.\n",
        "  for idx in range(len(pose_landmarks_list)):\n",
        "    pose_landmarks = pose_landmarks_list[idx]\n",
        "\n",
        "    # Draw the pose landmarks.\n",
        "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
        "    pose_landmarks_proto.landmark.extend([\n",
        "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
        "    ])\n",
        "    solutions.drawing_utils.draw_landmarks(\n",
        "      annotated_image,\n",
        "      pose_landmarks_proto,\n",
        "      solutions.pose.POSE_CONNECTIONS,\n",
        "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
        "  return annotated_image\n",
        "\n",
        "def calculate_distance(x1, y1, x2, y2):\n",
        "  return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "\n",
        "def perhitungan_elips(sb_mayor, sb_minor):\n",
        "  #hitung keliling elips\n",
        "  keliling_elips=0.5 * math.pi *(sb_mayor + sb_minor)\n",
        "  return keliling_elips\n",
        "\n",
        "def calculate_bbox_from_mask(mask):\n",
        "    indices = np.where(mask > 0)\n",
        "    y_min = np.min(indices[0])\n",
        "    y_max = np.max(indices[0])\n",
        "    x_min = np.min(indices[1])\n",
        "    x_max = np.max(indices[1])\n",
        "    y = y_max - y_min\n",
        "    x = x_max - x_min\n",
        "    if y > x:\n",
        "        width = y\n",
        "    else:\n",
        "        width = x\n",
        "    return [x_min, y_min, x_max, y_max], width"
      ],
      "metadata": {
        "id": "-JKx4lJv3Deg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FastSam():\n",
        "  def __init__(self, IMAGE_PATH):\n",
        "    self.path = IMAGE_PATH\n",
        "    self.image = cv2.imread(IMAGE_PATH, cv2.IMREAD_COLOR)\n",
        "\n",
        "#===============================================================================\n",
        "  def get_input_point(self):\n",
        "    base_options = python.BaseOptions(model_asset_path='pose_landmarker_lite.task')\n",
        "    options = vision.PoseLandmarkerOptions(\n",
        "        base_options=base_options,\n",
        "        output_segmentation_masks=True)\n",
        "    detector = vision.PoseLandmarker.create_from_options(options)\n",
        "    image = mp.Image.create_from_file(self.path)\n",
        "\n",
        "    detection_result = detector.detect(image)\n",
        "    pose_landmarks = detection_result.pose_landmarks\n",
        "\n",
        "    nose = pose_landmarks[0][0]\n",
        "    right_shoulder = pose_landmarks[0][12]\n",
        "    right_elbow = pose_landmarks[0][14]\n",
        "    right_wrist = pose_landmarks[0][16]\n",
        "    left_shoulder = pose_landmarks[0][11]\n",
        "    left_elbow = pose_landmarks[0][13]\n",
        "    left_wrist = pose_landmarks[0][15]\n",
        "    left_hip = pose_landmarks[0][23]\n",
        "    left_knee = pose_landmarks[0][25]\n",
        "    left_ankle = pose_landmarks[0][27]\n",
        "    right_hip = pose_landmarks[0][24]\n",
        "    right_knee = pose_landmarks[0][26]\n",
        "    right_ankle = pose_landmarks[0][28]\n",
        "\n",
        "    right_hand = calculate_distance(right_shoulder.x*image.width, right_shoulder.y*image.height, right_elbow.x*image.width, right_elbow.y*image.height) + calculate_distance(right_elbow.x*image.width, right_elbow.y*image.height, right_wrist.x*image.width, right_wrist.y*image.height)\n",
        "\n",
        "    left_hand = calculate_distance(left_shoulder.x*image.width, left_shoulder.y*image.height, left_elbow.x*image.width, left_elbow.y*image.height) + calculate_distance(left_elbow.x*image.width, left_elbow.y*image.height, left_wrist.x*image.width, left_wrist.y*image.height)\n",
        "\n",
        "    right_foot = calculate_distance(right_hip.x*image.width, right_hip.y*image.height, right_knee.x*image.width, right_knee.y*image.height) + calculate_distance(right_knee.x*image.width, right_knee.y*image.height, right_ankle.x*image.width, right_ankle.y*image.height)\n",
        "\n",
        "    left_foot = calculate_distance(left_hip.x*image.width, left_hip.y*image.height, left_knee.x*image.width, left_knee.y*image.height) + calculate_distance(left_knee.x*image.width, left_knee.y*image.height, left_ankle.x*image.width, left_ankle.y*image.height)\n",
        "\n",
        "    coords = np.array([\n",
        "        [nose.x*image.width,nose.y*image.height],\n",
        "        [right_shoulder.x*image.width,right_shoulder.y*image.height],\n",
        "        [left_shoulder.x*image.width,left_shoulder.y*image.height],\n",
        "        [right_elbow.x*image.width,right_elbow.y*image.height],\n",
        "        [left_elbow.x*image.width,left_elbow.y*image.height],\n",
        "        [right_wrist.x*image.width,right_wrist.y*image.height],\n",
        "        [left_wrist.x*image.width,left_wrist.y*image.height],\n",
        "        [right_hip.x*image.width,right_hip.y*image.height],\n",
        "        [left_hip.x*image.width,left_hip.y*image.height],\n",
        "        [right_knee.x*image.width,right_knee.y*image.height],\n",
        "        [left_knee.x*image.width,left_knee.y*image.height],\n",
        "        [right_ankle.x*image.width,right_ankle.y*image.height],\n",
        "        [left_ankle.x*image.width,left_ankle.y*image.height],\n",
        "        ])\n",
        "\n",
        "\n",
        "    annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
        "    segmentation_mask = detection_result.segmentation_masks[0].numpy_view()\n",
        "    visualized_mask = np.repeat(segmentation_mask[:, :, np.newaxis], 3, axis=2) * 255\n",
        "\n",
        "    return coords, right_foot, left_foot\n",
        "\n",
        "#===============================================================================\n",
        "  def munculkan_foto(self):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(self.image)\n",
        "    plt.title(f\"Hasil Gambar\")\n",
        "    plt.axis('on')\n",
        "    plt.show()\n",
        "\n",
        "  def munculkan_titik_mediapipe(self, coords, input_label):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(self.image)\n",
        "    show_points(coords, input_label, plt.gca())\n",
        "    plt.title(f\"Titik pada Tubuh\")\n",
        "    plt.axis('on')\n",
        "    plt.show()\n",
        "\n",
        "  def cek_masking(self, masks):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(self.image)\n",
        "    show_mask(masks, plt.gca())\n",
        "    plt.title(f\"Titik pada Tubuh\")\n",
        "    plt.axis('on')\n",
        "    plt.show()\n",
        "\n",
        "# Masking ====================================================================\n",
        "  def masking(self, input_point, input_label):\n",
        "    everything_results = model(self.path, device=DEVICE, retina_masks=True, imgsz=1024, conf=0.4, iou=0.9,)\n",
        "    prompt_process = FastSAMPrompt(self.path, everything_results, device=DEVICE)\n",
        "    mask = prompt_process.point_prompt(input_point, input_label)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "st2WWTjdm8PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perhitungan_Parameter():\n",
        "  def __init__(self, mask, IMAGE_PATH):\n",
        "    self.path = IMAGE_PATH\n",
        "    self.image = cv2.imread(IMAGE_PATH, cv2.IMREAD_COLOR)\n",
        "\n",
        "  def tarik_garis(mask, pointFrom_mediapipe):\n",
        "    indices = np.where(mask > 0)\n",
        "    indices_x = indices[2]\n",
        "    indices_y = indices[1]\n",
        "\n",
        "      # Cari nilai indices_x yang sama dengan nilai pointFrom_mediapipe indeks ke-0\n",
        "    val_poin_pose = int(pointFrom_mediapipe[0])  # Dapatkan nilai di indeks pertama dari pointFrom_mediapipe\n",
        "    matching_indices = [index for index, value in enumerate(indices_x) if value == val_poin_pose]  # Dapatkan indeks dari nilai val_poin_pose di indices_x\n",
        "    matching_indices_y_values = [indices_y[index] for index in matching_indices]  # Ambil nilai indices_y yang memiliki indeks yang sama dengan indices_x yang cocok\n",
        "\n",
        "    print(indices)\n",
        "    print(indices_x)\n",
        "    print(indices_y)\n",
        "    #print(\"Nilai indices_x yang cocok dengan,\", int(pointFrom_mediapipe[0]), \"adalah\", matching_indices)\n",
        "    #print(\"Nilai indices_y dengan indeks yang sama:\", matching_indices_y_values)\n",
        "    #print(indices[1])\n",
        "    #print(pointFrom_mediapipe)\n",
        "\n",
        "    # Temukan nilai maksimum dari daftar matching_indices_y_values\n",
        "    if matching_indices_y_values:\n",
        "        nilai_maksimum = max(matching_indices_y_values)\n",
        "        nilai_minimum = min(matching_indices_y_values)\n",
        "    else:\n",
        "        print(\"Tidak ada nilai yang cocok\")\n",
        "\n",
        "    return abs(nilai_maksimum-nilai_minimum)\n",
        "\n",
        "#=================================Deteksi Koin====================================\n",
        "  def detect(self):\n",
        "    model = torch.hub.load('.', 'custom', path='best.pt', source='local', force_reload=True)\n",
        "    # Image\n",
        "    # Inference\n",
        "    results = model(self.path)\n",
        "\n",
        "    # Results, change the flowing to: results.show()\n",
        "    df = results.pandas().xyxy[0]  # or .show(), .save(), .crop(), .pandas(), etc\n",
        "    df = df[df['confidence'] > 0.6]\n",
        "    df['x'] = df['xmax'] - df['xmin']\n",
        "    df['y'] = df['ymax'] - df['ymin']\n",
        "    df['x_tengah'] = (df['xmin'] + df['xmax']) / 2\n",
        "    df['y_tengah'] = (df['ymin'] + df['ymax']) / 2\n",
        "    df = df.sort_values('x')\n",
        "    df = df.reset_index()\n",
        "    x = df['x_tengah'][0]\n",
        "    y = df['y_tengah'][0]\n",
        "    # print(df)\n",
        "    coords = np.array([[x,y]])\n",
        "    lists = [df['xmin'][0], df['ymin'][0], df['xmax'][0], df['ymax'][0]]\n",
        "    width = lists[2] - lists[0]\n",
        "    height = lists[3] - lists[1]\n",
        "    if width > height:\n",
        "        width = height\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    return coords, lists, width"
      ],
      "metadata": {
        "id": "FcX7L7eYKDne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = FastSam('baby5-up.jpg')\n",
        "coords, right_foot, left_foot = image.get_input_point()\n",
        "coords = coords.astype(int)"
      ],
      "metadata": {
        "id": "nhvENBY59Ibo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image2 = FastSam('baby5-side2.jpeg')\n",
        "coords2, _, _ = image2.get_input_point()\n",
        "coords2 = coords2.astype(int)"
      ],
      "metadata": {
        "id": "45QNResCuBId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords2 = np.array([\n",
        "    [coords2[0][0], coords2[0][1]],\n",
        "    [coords2[2][0], coords2[2][1]],\n",
        "    [coords2[4][0], coords2[4][1]],\n",
        "    [coords2[6][0], coords2[6][1]],\n",
        "    [coords2[8][0], coords2[8][1]],\n",
        "    [coords2[10][0], coords2[10][1]],\n",
        "    [coords2[12][0], coords2[12][1]],\n",
        "    ])\n",
        "\n",
        "x_rightshoulder = coords[1][0]\n",
        "y_rightshoulder = coords[1][1]\n",
        "x_leftshoulder = coords[2][0]\n",
        "y_leftshoulder = coords[2][1]\n",
        "x_righthip = coords[5][0]\n",
        "y_righthip = coords[5][1]\n",
        "x_lefthip = coords[6][0]\n",
        "y_lefthip = coords[6][1]\n",
        "\n",
        "def coef(img):\n",
        "  real_coin_size = 2.7\n",
        "  coin_size = Perhitungan_Parameter(img).detect()[2]\n",
        "  coef = real_coin_size / coin_size\n",
        "  return coef\n",
        "\n",
        "koef_koin1 = coef('baby5-up.jpg')\n",
        "koef_koin2 = coef('baby5-side2.jpg')"
      ],
      "metadata": {
        "id": "LTHUiGPVuang"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all masking\n",
        "masking_kepala = image.masking(coords, input_label_kepala)\n",
        "masking_kepala2 = image2.masking(coords2, input_label_kepala2)\n",
        "masking_lengan = image.masking(coords, input_label_lengan)\n",
        "masking_lengan2 = image2.masking(coords2, input_label_lengan2)\n",
        "masking_paha = image.masking(coords, input_label_paha)\n",
        "masking_paha2 = image2.masking(coords2, input_label_paha2)\n",
        "\n",
        "# tarik garis\n",
        "garis_kepala = image.tarik_garis(masking_kepala, coords[0])*koef_koin1\n",
        "garis_kepala2 = image2.tarik_garis(masking_kepala2, coords2[0])*koef_koin2\n",
        "\n",
        "garis_lengan = image.tarik_garis(masking_lengan, coords[4])*koef_koin1\n",
        "garis_lengan2 = image2.tarik_garis(masking_lengan2, coords[2])*koef_koin2\n",
        "\n",
        "garis_paha = image.tarik_garis(masking_paha, coords[10])*koef_koin1\n",
        "garis_paha2 = image2.tarik_garis(masking_paha2, coords[5])*koef_koin2\n",
        "\n",
        "#perhitungan lingkar\n",
        "lingkar_kepala = perhitungan_elips(garis_kepala, garis_kepala2)\n",
        "lingkar_lengan = perhitungan_elips(garis_lengan, garis_lengan2)\n",
        "lingkar_paha = perhitungan_elips(garis_paha, garis_paha2)"
      ],
      "metadata": {
        "id": "-ZT4OCKSZ8n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tinggi_dada = masking_kepala2*0.7*koef_koin2\n",
        "tinggi_perut = masking_kepala2*0.8*koef_koin2\n",
        "\n",
        "lebar_dada=abs(y_rightshoulder-y_leftshoulder)*koef_koin1\n",
        "lebar_pinggang=(abs(y_righthip-y_lefthip)-0.4*abs(y_righthip-y_lefthip))*koef_koin1\n",
        "\n",
        "# perhitungan lingkar\n",
        "lingkar_dada = perhitungan_elips(tinggi_dada, lebar_dada)\n",
        "lingkar_perut = perhitungan_elips(tinggi_perut, lebar_pinggang)"
      ],
      "metadata": {
        "id": "SMJViLgoaAj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perhitungan_panjang_badan(koef_koin1, masking_kepala):\n",
        "  head_coordinate , _ = calculate_bbox_from_mask(masking_kepala[0])\n",
        "  x_min_kepala=head_coordinate[0]\n",
        "  x_max_kepala=head_coordinate[2]\n",
        "  panjang_kepala = abs(x_min_kepala-x_max_kepala)\n",
        "  panjang_badan=(abs(x_rightshoulder-x_righthip))\n",
        "  panjang_kaki= ((right_foot+left_foot)/2)\n",
        "\n",
        "  total_panjang_badan = (panjang_kepala + panjang_badan + panjang_kaki)*koef_koin1\n",
        "\n",
        "  return total_panjang_badan\n",
        "\n",
        "# panjang badan\n",
        "panjang_badan = perhitungan_panjang_badan(koef_koin1, input_label_kepala, masking_kepala)\n",
        "\n",
        "# semua parameter\n",
        "all_parameters = [panjang_badan, lingkar_dada, lingkar_perut, lingkar_kepala, lingkar_lengan, lingkar_paha]"
      ],
      "metadata": {
        "id": "tPq7_FlvbFQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################################################################################################"
      ],
      "metadata": {
        "id": "wu7UQ5xsbFNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def all_masking(coords, coords2, input_label_kepala, input_label_lengan, input_label_paha, input_label_kepala2, input_label_lengan2, input_label_paha2):\n",
        "  masking_kepala = image.masking(coords, input_label_kepala)\n",
        "  masking_kepala2 = image2.masking(coords2, input_label_kepala2)\n",
        "  masking_lengan = image.masking(coords, input_label_lengan)\n",
        "  masking_lengan2 = image2.masking(coords2, input_label_lengan2)\n",
        "  masking_paha = image.masking(coords, input_label_paha)\n",
        "  masking_paha2 = image2.masking(coords2, input_label_paha2)\n",
        "\n",
        "  return masking_kepala, masking_kepala2, masking_lengan, masking_lengan2, masking_paha, masking_paha2\n",
        "\n",
        "def perhitungan_lingkar(koef_koin1, koef_koin2, coords, coords2, masking_kepala, masking_kepala2, masking_lengan, masking_lengan2, masking_paha, masking_paha2):\n",
        "  garis_kepala = image.tarik_garis(masking_kepala, coords[0])*koef_koin1\n",
        "  garis_kepala2 = image2.tarik_garis(masking_kepala2, coords2[0])*koef_koin2\n",
        "\n",
        "  garis_lengan = image.tarik_garis(masking_lengan, coords[4])*koef_koin1\n",
        "  garis_lengan2 = image2.tarik_garis(masking_lengan2, coords[2])*koef_koin2\n",
        "\n",
        "  garis_paha = image.tarik_garis(masking_paha, coords[10])*koef_koin1\n",
        "  garis_paha2 = image2.tarik_garis(masking_paha2, coords[5])*koef_koin2\n",
        "\n",
        "\n",
        "  lingkar_kepala = perhitungan_elips(garis_kepala, garis_kepala2)\n",
        "  lingkar_lengan = perhitungan_elips(garis_lengan, garis_lengan2)\n",
        "  lingkar_paha = perhitungan_elips(garis_paha, garis_paha2)\n",
        "\n",
        "  return lingkar_kepala, lingkar_lengan, lingkar_paha\n",
        "\n",
        "def perhitungan_panjang_badan(koef_koin1, koef_koin2, input_label_kepala2, mask):\n",
        "  head_coordinate , _ = calculate_bbox_from_mask(mask[0])\n",
        "  x_min_kepala=head_coordinate[0]\n",
        "  x_max_kepala=head_coordinate[2]\n",
        "  panjang_kepala = abs(x_min_kepala-x_max_kepala)\n",
        "  panjang_badan=(abs(x_rightshoulder-x_righthip))\n",
        "  panjang_kaki= ((right_foot+left_foot)/2)\n",
        "\n",
        "  total_panjang_badan = (panjang_kepala + panjang_badan + panjang_kaki)*koef_koin1\n",
        "\n",
        "  return total_panjang_badan"
      ],
      "metadata": {
        "id": "hjYyTYthfS2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_masking = all_masking(coords, coords2, input_label_kepala, input_label_lengan, input_label_paha, input_label_kepala2, input_label_lengan2, input_label_paha2) #-> masking kepala\n"
      ],
      "metadata": {
        "id": "Qp-V_FK3zQQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hitung():\n",
        "  a = 1+1\n",
        "  b = 2+2\n",
        "  c = a+b\n",
        "  return a, b, c\n",
        "\n",
        "hitung = hitung()\n",
        "print(hitung[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq3hDGoX09eR",
        "outputId": "ded2fe8b-f8a3-4238-c4e5-3b85fee61c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    }
  ]
}