{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juaaju/Antropometri-Digital/blob/main/SAM_AND_POSE_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "45Mm4Xi8K0ht",
        "outputId": "ea4c9896-8e08-4811-a415-d1843a435fb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b_O34GqaK1Pc"
      },
      "outputs": [],
      "source": [
        "path_to_rar_file1 = '/content/drive/MyDrive/myProjek/ANTROPOMETRI/all.rar'\n",
        "path_to_rar_file2 = '/content/drive/MyDrive/myProjek/ANTROPOMETRI/model.rar'\n",
        "path_to_rar_file3 = '/content/drive/MyDrive/myProjek/ANTROPOMETRI/models.rar'\n",
        "path_to_rar_file4 = '/content/drive/MyDrive/myProjek/ANTROPOMETRI/utils.rar'\n",
        "extracted_folder = '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqBOsL5zK_0z",
        "outputId": "eb0c17e2-6019-46c2-e87a-474aceb60935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/myProjek/ANTROPOMETRI/all.rar\n",
            "\n",
            "Extracting  /content/.gitignore                                          \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/baby5-side2.jpeg                                    \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/baby5-up.jpeg                                       \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/data ukur bayi.xlsx                                 \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/detect.py                                           \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/export.py                                           \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/hubconf.py                                          \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/mediapipe-0.10.5-cp311-cp311-win_amd64.whl          \b\b\b\b  8%\b\b\b\b 16%\b\b\b\b 24%\b\b\b\b 32%\b\b\b\b 40%\b\b\b\b 47%\b\b\b\b 55%\b\b\b\b 63%\b\b\b\b 71%\b\b\b\b 79%\b\b\b\b 87%\b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  /content/model.py                                            \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  /content/Nasution et al_revision.pdf                         \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  /content/pacman                                              \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  /content/pose.py                                             \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  /content/PROGRES CODE UTAMA.pdf                              \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  /content/PROGRES CODE UTAMA.pptx                             \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/requirements.txt                                    \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/sam.py                                              \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/tempCodeRunnerFile.py                               \b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/myProjek/ANTROPOMETRI/model.rar\n",
            "\n",
            "Extracting  /content/pose_landmarker_lite.task                           \b\b\b\b 23%\b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  /content/best.pt                                             \b\b\b\b 49%\b\b\b\b 72%\b\b\b\b 95%\b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/myProjek/ANTROPOMETRI/models.rar\n",
            "\n",
            "Creating    /content/models                                           OK\n",
            "Extracting  /content/models/common.py                                    \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/custom_yolov5n.yaml                          \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/custom_yolov5s.yaml                          \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/experimental.py                              \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Creating    /content/models/hub                                       OK\n",
            "Extracting  /content/models/hub/anchors.yaml                             \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov3-spp.yaml                          \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov3-tiny.yaml                         \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov3.yaml                              \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-bifpn.yaml                        \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-fpn.yaml                          \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-p2.yaml                           \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-p34.yaml                          \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-p6.yaml                           \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-p7.yaml                           \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5-panet.yaml                        \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5l6.yaml                            \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5m6.yaml                            \b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5n6.yaml                            \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5s-ghost.yaml                       \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5s-transformer.yaml                 \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5s6.yaml                            \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/hub/yolov5x6.yaml                            \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/tf.py                                        \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolo.py                                      \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolov5l.yaml                                 \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolov5m.yaml                                 \b\b\b\b 59%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolov5n.yaml                                 \b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolov5s.yaml                                 \b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/yolov5x.yaml                                 \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/__init__.py                                  \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Creating    /content/models/__pycache__                               OK\n",
            "Extracting  /content/models/__pycache__/common.cpython-310.pyc           \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/__pycache__/experimental.cpython-310.pyc     \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/__pycache__/yolo.cpython-310.pyc             \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/models/__pycache__/__init__.cpython-310.pyc         \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/myProjek/ANTROPOMETRI/utils.rar\n",
            "\n",
            "No files to extract\n"
          ]
        }
      ],
      "source": [
        "!apt-get -qq install -y unrar\n",
        "!unrar x {path_to_rar_file1} {extracted_folder}\n",
        "!unrar x {path_to_rar_file2} {extracted_folder}\n",
        "!unrar x {path_to_rar_file3} {extracted_folder}\n",
        "!unrar x {path_to_rar_file4} {extracted_folder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJdZXUKuLN0K"
      },
      "outputs": [],
      "source": [
        "pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flujjh9IMa_d"
      },
      "outputs": [],
      "source": [
        "using_colab = True\n",
        "if using_colab:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"Torchvision version:\", torchvision.__version__)\n",
        "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAjTVZfgFGBu"
      },
      "source": [
        "# Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtHoBGrvEiH9"
      },
      "outputs": [],
      "source": [
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import cv2\n",
        "from mediapipe import solutions\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX9Bp6oIFIBe"
      },
      "source": [
        "# Landmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbnbXnHHEqPr"
      },
      "outputs": [],
      "source": [
        "# Fungsi Landmark\n",
        "def draw_landmarks_on_image(rgb_image, detection_result):\n",
        "  pose_landmarks_list = detection_result.pose_landmarks\n",
        "  annotated_image = np.copy(rgb_image)\n",
        "\n",
        "  # Loop through the detected poses to visualize.\n",
        "  for idx in range(len(pose_landmarks_list)):\n",
        "    pose_landmarks = pose_landmarks_list[idx]\n",
        "\n",
        "    # Draw the pose landmarks.\n",
        "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
        "    pose_landmarks_proto.landmark.extend([\n",
        "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
        "    ])\n",
        "    solutions.drawing_utils.draw_landmarks(\n",
        "      annotated_image,\n",
        "      pose_landmarks_proto,\n",
        "      solutions.pose.POSE_CONNECTIONS,\n",
        "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
        "  return annotated_image\n",
        "\n",
        "#Fungsi Menghitung Jarak\n",
        "def calculate_distance(x1, y1, x2, y2):\n",
        "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "\n",
        "#Fungsi Ngambil Koordinat Pose\n",
        "def get_input_point(image):\n",
        "  base_options = python.BaseOptions(model_asset_path='pose_landmarker_lite.task')\n",
        "  options = vision.PoseLandmarkerOptions(\n",
        "      base_options=base_options,\n",
        "      output_segmentation_masks=True)\n",
        "  detector = vision.PoseLandmarker.create_from_options(options)\n",
        "  image = mp.Image.create_from_file(image)\n",
        "\n",
        "  detection_result = detector.detect(image)\n",
        "  pose_landmarks = detection_result.pose_landmarks\n",
        "\n",
        "  nose = pose_landmarks[0][0]\n",
        "  right_shoulder = pose_landmarks[0][12]\n",
        "  right_elbow = pose_landmarks[0][14]\n",
        "  right_wrist = pose_landmarks[0][16]\n",
        "  left_shoulder = pose_landmarks[0][11]\n",
        "  left_elbow = pose_landmarks[0][13]\n",
        "  left_wrist = pose_landmarks[0][15]\n",
        "  left_hip = pose_landmarks[0][23]\n",
        "  left_knee = pose_landmarks[0][25]\n",
        "  left_ankle = pose_landmarks[0][27]\n",
        "  right_hip = pose_landmarks[0][24]\n",
        "  right_knee = pose_landmarks[0][26]\n",
        "  right_ankle = pose_landmarks[0][28]\n",
        "\n",
        "  right_hand = calculate_distance(right_shoulder.x*image.width, right_shoulder.y*image.height, right_elbow.x*image.width, right_elbow.y*image.height) + calculate_distance(right_elbow.x*image.width, right_elbow.y*image.height, right_wrist.x*image.width, right_wrist.y*image.height)\n",
        "\n",
        "  left_hand = calculate_distance(left_shoulder.x*image.width, left_shoulder.y*image.height, left_elbow.x*image.width, left_elbow.y*image.height) + calculate_distance(left_elbow.x*image.width, left_elbow.y*image.height, left_wrist.x*image.width, left_wrist.y*image.height)\n",
        "\n",
        "  right_foot = calculate_distance(right_hip.x*image.width, right_hip.y*image.height, right_knee.x*image.width, right_knee.y*image.height) + calculate_distance(right_knee.x*image.width, right_knee.y*image.height, right_ankle.x*image.width, right_ankle.y*image.height)\n",
        "\n",
        "  left_foot = calculate_distance(left_hip.x*image.width, left_hip.y*image.height, left_knee.x*image.width, left_knee.y*image.height) + calculate_distance(left_knee.x*image.width, left_knee.y*image.height, left_ankle.x*image.width, left_ankle.y*image.height)\n",
        "\n",
        "  coords = np.array([\n",
        "      [nose.x*image.width,nose.y*image.height],\n",
        "      [right_shoulder.x*image.width,right_shoulder.y*image.height],\n",
        "      [left_shoulder.x*image.width,left_shoulder.y*image.height],\n",
        "      [right_elbow.x*image.width,right_elbow.y*image.height],\n",
        "      [left_elbow.x*image.width,left_elbow.y*image.height],\n",
        "      [right_wrist.x*image.width,right_wrist.y*image.height],\n",
        "      [left_wrist.x*image.width,left_wrist.y*image.height],\n",
        "      [right_hip.x*image.width,right_hip.y*image.height],\n",
        "      [left_hip.x*image.width,left_hip.y*image.height],\n",
        "      [right_knee.x*image.width,right_knee.y*image.height],\n",
        "      [left_knee.x*image.width,left_knee.y*image.height],\n",
        "      [right_ankle.x*image.width,right_ankle.y*image.height],\n",
        "      [left_ankle.x*image.width,left_ankle.y*image.height],\n",
        "      ])\n",
        "\n",
        "\n",
        "  annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
        "  segmentation_mask = detection_result.segmentation_masks[0].numpy_view()\n",
        "  visualized_mask = np.repeat(segmentation_mask[:, :, np.newaxis], 3, axis=2) * 255\n",
        "\n",
        "  return coords, right_foot, left_foot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwz5Gf6RFNTn"
      },
      "source": [
        "# Persiapan Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx1bm6PVTRwG"
      },
      "outputs": [],
      "source": [
        "#load model\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "predictor = SamPredictor(sam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAKkjv-4EwQA"
      },
      "outputs": [],
      "source": [
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ9HNkhKmT1w"
      },
      "outputs": [],
      "source": [
        "def masking(input_point, input_label):\n",
        "  masks, scores, logits = predictor.predict(\n",
        "    point_coords=input_point,\n",
        "    point_labels=input_label,\n",
        "    multimask_output=True,\n",
        ")\n",
        "\n",
        "  mask_input = logits[np.argmax(scores), :, :]\n",
        "\n",
        "  masks, _, _ = predictor.predict(\n",
        "    point_coords=input_point,\n",
        "    point_labels=input_label,\n",
        "    mask_input=mask_input[None, :, :],\n",
        "    multimask_output=False,\n",
        ")\n",
        "  return masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckchIBszFSea"
      },
      "source": [
        "# Yolo deteksi koin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sDz0n33E2_f"
      },
      "outputs": [],
      "source": [
        "#=================================Deteksi Koin====================================\n",
        "def detect(img):\n",
        "    model = torch.hub.load('.', 'custom', path='best.pt', source='local', force_reload=True)\n",
        "    # Image\n",
        "    # Inference\n",
        "    results = model(img)\n",
        "\n",
        "    # Results, change the flowing to: results.show()\n",
        "    df = results.pandas().xyxy[0]  # or .show(), .save(), .crop(), .pandas(), etc\n",
        "    df = df[df['confidence'] > 0.5]\n",
        "    df['x'] = df['xmax'] - df['xmin']\n",
        "    df['y'] = df['ymax'] - df['ymin']\n",
        "    df['x_tengah'] = (df['xmin'] + df['xmax']) / 2\n",
        "    df['y_tengah'] = (df['ymin'] + df['ymax']) / 2\n",
        "    df = df.sort_values('x')\n",
        "    df = df.reset_index()\n",
        "    x = df['x_tengah'][0]\n",
        "    y = df['y_tengah'][0]\n",
        "    # print(df)\n",
        "    coords = np.array([[x,y]])\n",
        "    lists = [df['xmin'][0], df['ymin'][0], df['xmax'][0], df['ymax'][0]]\n",
        "    width = lists[2] - lists[0]\n",
        "    height = lists[3] - lists[1]\n",
        "    if width > height:\n",
        "        width = height\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    return coords, lists, width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjV-F6T6FVUx"
      },
      "outputs": [],
      "source": [
        "def coef(img):\n",
        "  real_coin_size = 2.7\n",
        "  coin_size = detect(img)[2]\n",
        "  coef = real_coin_size / coin_size\n",
        "  return coef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q7-aeX6nBCV"
      },
      "outputs": [],
      "source": [
        "koin1=coef('baby5-up.jpeg')\n",
        "koin2=coef('baby5-side2.jpeg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gfOv0vBJSkL"
      },
      "source": [
        "# Kalkulasi Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlAgiqNZJSb0"
      },
      "outputs": [],
      "source": [
        "def tarik_garis(mask, poin_pose):\n",
        "  indices = np.where(mask > 0)\n",
        "  indices_x = indices[2]\n",
        "  indices_y = indices[1]\n",
        "\n",
        "    # Cari nilai indices_x yang sama dengan nilai poin_pose indeks ke-0\n",
        "  val_poin_pose = int(poin_pose[0])  # Dapatkan nilai di indeks pertama dari poin_pose\n",
        "  matching_indices = [index for index, value in enumerate(indices_x) if value == val_poin_pose]  # Dapatkan indeks dari nilai val_poin_pose di indices_x\n",
        "  matching_indices_y_values = [indices_y[index] for index in matching_indices]  # Ambil nilai indices_y yang memiliki indeks yang sama dengan indices_x yang cocok\n",
        "\n",
        "  print(indices)\n",
        "  print(indices_x)\n",
        "  print(indices_y)\n",
        "  #print(\"Nilai indices_x yang cocok dengan,\", int(poin_pose[0]), \"adalah\", matching_indices)\n",
        "  #print(\"Nilai indices_y dengan indeks yang sama:\", matching_indices_y_values)\n",
        "  #print(indices[1])\n",
        "  #print(poin_pose)\n",
        "\n",
        "  # Temukan nilai maksimum dari daftar matching_indices_y_values\n",
        "  if matching_indices_y_values:\n",
        "      nilai_maksimum = max(matching_indices_y_values)\n",
        "      nilai_minimum = min(matching_indices_y_values)\n",
        "  else:\n",
        "      print(\"Tidak ada nilai yang cocok\")\n",
        "\n",
        "  return abs(nilai_maksimum-nilai_minimum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WRgVKWw1Aa9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCoKn1tzJdUQ"
      },
      "outputs": [],
      "source": [
        "def calculate_bbox_from_mask(mask):\n",
        "    indices = np.where(mask > 0)\n",
        "    y_min = np.min(indices[0])\n",
        "    y_max = np.max(indices[0])\n",
        "    x_min = np.min(indices[1])\n",
        "    x_max = np.max(indices[1])\n",
        "    y = y_max - y_min\n",
        "    x = x_max - x_min\n",
        "    if y > x:\n",
        "        width = y\n",
        "    else:\n",
        "        width = x\n",
        "    return [x_min, y_min, x_max, y_max], width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c86tJ7OJ4Gz"
      },
      "outputs": [],
      "source": [
        "def perhitungan(sb_mayor, sb_minor):\n",
        "  #hitung keliling elips\n",
        "  keliling_elips=0.5 * math.pi *(sb_mayor + sb_minor)\n",
        "  return keliling_elips\n",
        "\n",
        "def perhitungan2(mask, mask2, img1):\n",
        "  #hitung tinggi dada dengan masking segmentation\n",
        "  #body_coord, _ = calculate_bbox_from_mask(mask2)\n",
        "  #rint(body_coord)\n",
        "\n",
        "  #y_max_body=body_coord[1]\n",
        "  #y_min_body=body_coord[3]\n",
        "  #tinggi_dada=abs(y_max_body-y_min_body)*coef/10 #digunakan juga untuk lingkar perut\n",
        "  #print(y_max_body)\n",
        "\n",
        "  #hitung panjang badan, lebar dada, lebar perut dengan pose landmark koordinat\n",
        "  coords, right_foot, left_foot = get_input_point(img1)\n",
        "  x_rightshoulder = coords[1][0]\n",
        "  y_rightshoulder = coords[1][1]\n",
        "  x_leftshoulder = coords[2][0]\n",
        "  y_leftshoulder = coords[2][1]\n",
        "  x_righthip = coords[5][0]\n",
        "  y_righthip = coords[5][1]\n",
        "  x_lefthip = coords[6][0]\n",
        "  y_lefthip = coords[6][1]\n",
        "\n",
        "  head_coordinate , _ = calculate_bbox_from_mask(mask[0])\n",
        "  #print(head_coordinate)\n",
        "  x_min_kepala=head_coordinate[0]\n",
        "  #print(x_min_kepala)\n",
        "  x_max_kepala=head_coordinate[2]\n",
        "  #print(x_max_kepala)\n",
        "  panjang_kepala = abs(x_min_kepala-x_max_kepala)\n",
        "  #print(panjang_kepala*koefisien/10)\n",
        "\n",
        "  panjang_badan=(abs(x_rightshoulder-x_righthip))\n",
        "  #print(panjang_badan*koefisien/10)\n",
        "\n",
        "  panjang_kaki= ((right_foot+left_foot)/2) #di bagi 2 (panjang kaki keduanya dijumlah dan dibagi 2)\n",
        "  #print(panjang_kaki*koefisien/10)\n",
        "\n",
        "  badan_coord , _ = calculate_bbox_from_mask(mask2[0])\n",
        "  y_min_badan=badan_coord[1]\n",
        "  y_max_badan=badan_coord[3]\n",
        "  tinggi_dada = abs(y_min_badan-y_max_badan)*koin2\n",
        "  #print(y_min_badan, y_max_badan)\n",
        "\n",
        "  total_bdn = (panjang_kepala + panjang_badan + panjang_kaki)*koin1\n",
        "  #print(\"panjang bayi: \", total_bdn, \"cm\")\n",
        "\n",
        "  lebar_dada=abs(y_rightshoulder-y_leftshoulder)*koin1\n",
        "  #print(\"lebar dada: \", lebar_dada, \"cm\")\n",
        "\n",
        "  lebar_pinggang=(abs(y_righthip-y_lefthip)-0.4*abs(y_righthip-y_lefthip))*koin1\n",
        "  #print(\"lebar pinggang: \", lebar_pinggang, \"cm\")\n",
        "\n",
        "  return total_bdn, lebar_dada, lebar_pinggang, tinggi_dada, panjang_kepala"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK7mTdc4Jd0u"
      },
      "source": [
        "# Proses dan Kalkulasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs3tX2Bdmi4U"
      },
      "outputs": [],
      "source": [
        "#variabel tetap\n",
        "input_label_kepala = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "input_label_paha = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
        "input_label_lengan = np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "\n",
        "input_label_kepala2 = np.array([1, 0, 0, 0, 0, 0, 0])\n",
        "input_label_paha2 = np.array([0, 0, 0, 0, 0, 1, 0])\n",
        "input_label_lengan2 = np.array([0, 0, 1, 0, 0, 0, 0])\n",
        "input_label_badan = np.array([0, 1, 0, 0, 0, 0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPdb0aRJW95V"
      },
      "outputs": [],
      "source": [
        "def all_parameter(img1, img2):\n",
        "  #proses 1\n",
        "  coords, right_foot, left_foot=get_input_point(img1)\n",
        "  input_poin1 = coords\n",
        "  image_read = cv2.imread(img1)\n",
        "  image = cv2.cvtColor(image_read, cv2.COLOR_BGR2RGB)\n",
        "  predictor.set_image(image)\n",
        "\n",
        "  masking_kepala=masking(input_poin1, input_label_kepala)\n",
        "  masking_lengan=masking(input_poin1, input_label_lengan)\n",
        "  masking_paha=masking(input_poin1, input_label_paha)\n",
        "\n",
        "  #proses 2\n",
        "  coords2, _, _=get_input_point(img2)\n",
        "\n",
        "  input_poin2 = np.array([\n",
        "      [coords2[0][0], coords2[0][1]],\n",
        "      [coords2[2][0], coords2[2][1]],\n",
        "      [coords2[4][0], coords2[4][1]],\n",
        "      [coords2[6][0], coords2[6][1]],\n",
        "      [coords2[8][0], coords2[8][1]],\n",
        "      [coords2[10][0], coords2[10][1]],\n",
        "      [coords2[12][0], coords2[12][1]],\n",
        "      ])\n",
        "\n",
        "  image_read2 = cv2.imread(img2)\n",
        "  image2 = cv2.cvtColor(image_read2, cv2.COLOR_BGR2RGB)\n",
        "  predictor.set_image(image2)\n",
        "\n",
        "  masking_kepala2=masking(input_poin2, input_label_kepala2)\n",
        "  masking_lengan2=masking(input_poin2, input_label_lengan2)\n",
        "  masking_paha2=masking(input_poin2, input_label_paha2)\n",
        "  masking_badan=masking(input_poin2, input_label_badan)\n",
        "\n",
        "  #perhitungan\n",
        "  garis_kepala_depan=tarik_garis(masking_kepala, input_poin1[0])*koin1\n",
        "  garis_lengan_depan=tarik_garis(masking_lengan, input_poin1[4])*koin1\n",
        "  garis_paha_depan=tarik_garis(masking_paha, input_poin1[10])*koin1\n",
        "  garis_kepala_samping=tarik_garis(masking_kepala2, input_poin2[0])*koin2\n",
        "  garis_lengan_samping=tarik_garis(masking_lengan2, input_poin2[2])*koin2\n",
        "  garis_paha_samping=tarik_garis(masking_paha2, input_poin2[5])*koin2\n",
        "  garis_badan_samping=tarik_garis(masking_badan, input_poin2[1])*koin2\n",
        "\n",
        "  total_bdn, lebar_dada, lebar_pinggang, tinggi_dada, panjang_kepala = perhitungan2(masking_kepala, masking_badan, img1)\n",
        "\n",
        "  lingkar_kepala = perhitungan(garis_kepala_depan, garis_kepala_samping)\n",
        "  lingkar_lengan = perhitungan(garis_lengan_depan, garis_lengan_samping)\n",
        "  lingkar_paha = perhitungan(garis_paha_depan, garis_paha_samping)\n",
        "  lingkar_perut= perhitungan(lebar_pinggang, tinggi_dada)\n",
        "  lingkar_dada= perhitungan(lebar_dada, tinggi_dada)\n",
        "  total_panjang_bayi= total_bdn\n",
        "\n",
        "  return lingkar_kepala, lingkar_lengan, lingkar_paha, lingkar_perut, lingkar_dada, total_panjang_bayi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DnjRvLU1c_I"
      },
      "outputs": [],
      "source": [
        "def all_parameter(img1):\n",
        "  #proses 1\n",
        "  coords, right_foot, left_foot=get_input_point(img1)\n",
        "  input_poin1 = coords\n",
        "  image_read = cv2.imread(img1)\n",
        "  image = cv2.cvtColor(image_read, cv2.COLOR_BGR2RGB)\n",
        "  predictor.set_image(image)\n",
        "\n",
        "  masking_kepala=masking(input_poin1, input_label_kepala)\n",
        "  masking_lengan=masking(input_poin1, input_label_lengan)\n",
        "  masking_paha=masking(input_poin1, input_label_paha)\n",
        "\n",
        "  garis_kepala_depan=tarik_garis(masking_kepala, input_poin1[0])*koin1\n",
        "  garis_lengan_depan=tarik_garis(masking_lengan, input_poin1[4])*koin1\n",
        "  garis_paha_depan=tarik_garis(masking_paha, input_poin1[10])*koin1\n",
        "\n",
        "  print(garis_kepala_depan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSKXphFrZDCB"
      },
      "outputs": [],
      "source": [
        "print(all_parameter('baby5-up.jpeg'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOAyegxvcHMUUZCiHp19wZL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}